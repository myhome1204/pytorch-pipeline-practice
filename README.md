# pytorch-pipeline-practice

ìºê¸€ì˜ ê³ ì–‘ì´/ê°•ì•„ì§€ ì´ì§„ ë¶„ë¥˜ ì˜ˆì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ CNN í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì—°ìŠµ

ë‹¨ìˆœ ëª¨ë¸ êµ¬í˜„ì— ê·¸ì¹˜ì§€ ì•Šê³ , í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰, ë¡œê¹…, ì‹œê°í™”, ì‹¤í—˜ ì¶”ì  ë“± ë‹¤ì–‘í•œ ì‹¤í—˜ ê´€ë¦¬ ë„êµ¬ë¥¼ ì ìš©

ê²°ê³¼ ì„±ëŠ¥ë³´ë‹¤ ML ì‹¤ë¬´ íŒŒì´í”„ë¼ì¸ íë¦„ì„ ìµíˆëŠ” ë° ì´ˆì 

ìºê¸€ ì •ë‹µ ë°ì´í„°ê°€ ì—†ì–´ inference(ì˜ˆì¸¡) ëª¨ë“ˆì€ í¬í•¨ë˜ì§€ ì•ŠìŒ

â€» ë¡œê·¸ íŒŒì¼ì€ ìš©ëŸ‰ ë° ìˆ˜ê°€ ë§ì•„ Git ì €ì¥ì†Œì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥ ìš”ì•½ (Features)

PyTorch ê¸°ë°˜ CNN ëª¨ë¸ í•™ìŠµ êµ¬ì¡° êµ¬í˜„

Ray Tuneì„ í†µí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ (lr, batch_size, weight_decay)

MLflowë¥¼ í™œìš©í•œ ì‹¤í—˜ ê¸°ë¡ ë° ì‹œê°í™”

TensorBoardë¥¼ ì´ìš©í•œ í•™ìŠµ ê³¡ì„  ë° gradient íë¦„ ì‹œê°í™”

EarlyStopping, Learning Rate Scheduler ì ìš©

## ğŸ›  ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ (Tech Stack)

Framework: PyTorch, torchvision

Experiment Tracking: MLflow, TensorBoard

Hyperparameter Tuning: Ray Tune

Logging & Config: logging, argparse

Automation: Shell script (.sh)

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
â”œâ”€â”€ main.py # (Train)ì‹¤í–‰ ì§„ì…ì 
â”œâ”€â”€ requirements.txt # íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ README.md # í”„ë¡œì íŠ¸ ì„¤ëª…
â”œâ”€â”€ .env # í™˜ê²½ë³€ìˆ˜ (ë¡œì»¬ ê²½ë¡œ ë“±)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ checkpoint.pt # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ configs/ # í•™ìŠµ/íŠœë‹ ì„¤ì • íŒŒì¼
â”‚ â”œâ”€â”€ train/
â”‚ â””â”€â”€ tune/
â”‚
â”œâ”€â”€ data/ # ë°ì´í„° ë””ë ‰í† ë¦¬
â”‚ â”œâ”€â”€ raw/ # ì›ë³¸ ë°ì´í„°
â”‚ â””â”€â”€ processed/ # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚
â”œâ”€â”€ logs/ # ë¡œê·¸ ê´€ë ¨ ë””ë ‰í† ë¦¬
â”‚ â”œâ”€â”€ logging/ # logging ëª¨ë“ˆ ë¡œê·¸
â”‚ â”œâ”€â”€ mlflow/ # MLflow ì‹¤í—˜ ì¶”ì  ë¡œê·¸
â”‚ â””â”€â”€ tensorboard/ # TensorBoard ë¡œê·¸
â”‚
â”œâ”€â”€ models/ # (ì €ì¥ëª¨ë¸)
â”‚ â”œâ”€â”€ model.pth # ì €ì¥ëœ ëª¨ë¸ íŒŒì¼
â”‚
â”œâ”€â”€ outputs/ # ì‹¤í—˜ ê²°ê³¼ ì €ì¥
â”‚ â”œâ”€â”€ experiments/ # ëª¨ë¸/ê²°ê³¼ ì €ì¥
â”‚ â”œâ”€â”€ hparam/ # Ray Tune íŠœë‹ ê²°ê³¼
â”‚ â””â”€â”€ inference_results/ # ì˜ˆì¸¡ ê²°ê³¼
â”‚
â”œâ”€â”€ scripts/ # ì‹¤í–‰ìš© ì‰˜ ìŠ¤í¬ë¦½íŠ¸
â”‚ â”œâ”€â”€ train/
â”‚ â””â”€â”€ tune/train_exp1_full.sh
â”‚
â””â”€â”€ src/ # ì†ŒìŠ¤ ì½”ë“œ
â”œâ”€â”€ pycache/
â”œâ”€â”€ dataset.py # ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
â”œâ”€â”€ early_stopping.py # EarlyStopping ì½œë°±
â”œâ”€â”€ logger_utils.py # ì»¤ìŠ¤í…€ ë¡œê¹… ì„¤ì •
â”œâ”€â”€ model.py # CNN ëª¨ë¸ ì •ì˜
â”œâ”€â”€ train.py # í•™ìŠµ ë¡œì§
â”œâ”€â”€ utils.py # ê¸°íƒ€ ìœ í‹¸ í•¨ìˆ˜
â””â”€â”€ tune/ # Ray Tune ê´€ë ¨ ì½”ë“œ(train_fn,run_tuner,tune_utils ë“±)
```

## âš™ï¸ ì‹¤í–‰ ë°©ë²• (Usage)

### 1ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ (Ray Tune ì‚¬ìš©)
configs/tune/search_full.yamlì„ ê¸°ë°˜ìœ¼ë¡œ lr, batch_size, weight_decay ë“±ì„ íƒìƒ‰
```
bash scripts/tune/train_exp1_full.sh
```
ì‹¤í–‰ ì‹œ ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ Python ëª…ë ¹ì´ ì‹¤í–‰
```
python src/tune/run_tuner.py \
  --name ray_exp1 \
  --config_file configs/tune/search_full.yaml \
  --num_samples 30 \
  --max_num_epochs 20 \
  --min_num_epochs 5 \
  --train_data_path "$TRAIN_DATA_PATH" \
  --gpus_per_trial 1 \
  --storage_path "$STORAGE_PATH" \
  --logging_path logs/logging/tune/ray_exp1.log \
  --logging_basic_level DEBUG \
  --logging_console_level INFO \
  --logging_file_level INFO \
  --save_path outputs/hparam
```

### 2ï¸âƒ£ ëª¨ë¸ í•™ìŠµ (main.py + JSON config ì‚¬ìš©)

ì„ íƒëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ í•™ìŠµì„ ìˆ˜í–‰
configëŠ” configs/train/train_config.jsonì— ì •ì˜
```
python main.py --config_file configs/train/train_config.json
```
ì‹¤í–‰ ì‹œ ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ Python ëª…ë ¹ì´ ì‹¤í–‰

```
{
  "train_path": "data/raw/train.csv",
  "test_path" : "data/raw/test.csv",
  "lr": 0.00046,
  "batch_size": 64,
  "optimizer": "adam",
  "weight_decay": 0.00044,
  "logging_path": "logs/logging/train/train2.log",
  "logging_basic_level": "DEBUG",
  "logging_console_level": "INFO",
  "logging_file_level": "INFO",
  "mlflow_log_path": "logs/mlflow/train",
  "tensorboard_log_path": "logs/tensorboard/train/train2",
  "scheduler_patience": 3,
  "scheduler_lr_factor": 0.5,
  "scheduler_mode": "min",
  "earlystop_patience": 3,
  "earlystop_delta": 0.001,
  "earlystop_mode": "min"
}
```


